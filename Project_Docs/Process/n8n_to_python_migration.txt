===================================================================
Python 코드로 이관 작업 완료 가이드
===================================================================

작업 일자: 2026-01-21
작업자: AI Assistant
목표: n8n 워크플로우를 Python(FastAPI) 기반 시스템으로 전환

===================================================================
1. 완료된 작업 목록
===================================================================

1.1 프로젝트 구조 생성 (모듈러 모놀리스)
-------------------------------------------------------------------
    Back/
    ├── __init__.py
    ├── main.py                    # FastAPI 앱 엔트리포인트
    ├── core/                      # 공통 기능
    │   ├── __init__.py
    │   ├── config.py              # 환경 변수 관리
    │   └── database.py            # DB 연결 및 세션
    └── trend/                     # 트렌드 도메인 (Package by Feature)
        ├── __init__.py
        ├── models.py              # DB 모델 (Keyword, Instagram, YouTube, News)
        ├── schemas.py             # Pydantic 검증 스키마
        ├── collector.py           # 외부 API 호출 (Apify, YouTube, RSS)
        ├── service.py             # 비즈니스 로직 (워크플로우 오케스트레이션)
        └── router.py              # FastAPI 엔드포인트

1.2 주요 기능 구현
-------------------------------------------------------------------
    (1) ApifyCollector
        - Google Trends 수집 (5개국 동시 지원)
        - Instagram 해시태그 검색
        
    (2) YouTubeCollector
        - YouTube Data API v3 비디오 검색
        
    (3) NewsCollector
        - Google News RSS 피드 파싱
        
    (4) TrendService
        - 일일 트렌드 수집 파이프라인 (n8n Daily Trigger 대체)
        - 수동 키워드 검색 (n8n Keyword Form 대체)
        - 키워드별 집계 업데이트 (instagram_posts, youtube_videos, news_count, score)

1.3 n8n 대비 개선 사항
-------------------------------------------------------------------
    구분                n8n                          Python
    -------------------------------------------------------------------
    데이터 저장          Google Sheets               PostgreSQL (관계형)
    데이터 중복          수동 관리 필요               UNIQUE 제약조건 자동 처리
    로직 가독성          JS Code 노드 (복잡)          Python Class (명확)
    에러 핸들링          제한적                      try-except + 로그
    확장성              노드 추가 시 복잡해짐         모듈 추가 간편
    GenAI 연동          제한적                      OpenAI SDK 직접 제어 가능
    비용                n8n 서버 유지비              자체 서버만 필요

===================================================================
2. 다음 단계 (사용자 작업 필요)
===================================================================

2.1 환경 변수 설정
-------------------------------------------------------------------
    (1) .env.example을 복사하여 .env 파일 생성
        명령어: copy .env.example .env
    
    (2) .env 파일에 실제 API 키 입력
        - APIFY_TOKEN: Apify 계정에서 발급
        - YOUTUBE_API_KEY: Google Cloud Console에서 발급
        - OPENAI_API_KEY: OpenAI 계정에서 발급
        - DATABASE_URL: PostgreSQL 연결 문자열

2.2 데이터베이스 초기화
-------------------------------------------------------------------
    (1) PostgreSQL 컨테이너 실행 (docker-compose.yml 사용)
        명령어: docker-compose up -d
    
    (2) Alembic 초기화
        명령어: alembic init alembic
    
    (3) alembic/env.py 수정 (아래 내용 추가 필요)
        - import sys, os 추가
        - sys.path.insert(0, os.path.abspath("."))
        - from Back.core.database import Base
        - from Back.trend import models
        - target_metadata = Base.metadata
    
    (4) 마이그레이션 파일 생성
        명령어: alembic revision --autogenerate -m "create trend tables"
    
    (5) 마이그레이션 실행
        명령어: alembic upgrade head

2.3 서버 실행
-------------------------------------------------------------------
    명령어: uvicorn Back.main:app --reload --host 0.0.0.0 --port 8000
    
    접속 주소:
        - API 루트: http://localhost:8000
        - API 문서: http://localhost:8000/docs
        - 트렌드 수집: POST http://localhost:8000/trend/collect-daily

2.4 API 테스트
-------------------------------------------------------------------
    (1) 일일 트렌드 수집
        POST /trend/collect-daily
        Body:
        {
            "countries": ["KR", "JP"],
            "top_n_per_country": 10
        }
    
    (2) 수동 키워드 검색
        POST /trend/collect-manual
        Body:
        {
            "keywords": ["AI", "ChatGPT", "비트코인"],
            "country": "KR"
        }
    
    (3) 상위 키워드 조회
        GET /trend/keywords/top?country=KR&limit=20

===================================================================
3. 추가 구현 필요 사항 (향후 작업)
===================================================================

3.1 GenAI 분석 모듈 (analyzer.py)
-------------------------------------------------------------------
    - OpenAI API를 사용하여 수집된 데이터 분석
    - 프롬프트 엔지니어링으로 "핫이슈" 선별
    - 시뮬레이션 로직 구현

3.2 콘텐츠 발행 모듈 (publisher.py)
-------------------------------------------------------------------
    - Instagram/Threads 자동 업로드
    - 이미지 생성 (PIL, Canvas API 등)
    - 승인 후 업로드 / 완전 자동 업로드 옵션

3.3 스케줄러 설정
-------------------------------------------------------------------
    - APScheduler 또는 Celery를 사용하여 매일 오전 6시 자동 실행
    - 예시: @scheduler.scheduled_job('cron', hour=6)

3.4 UI 구현 (선택 사항)
-------------------------------------------------------------------
    - React 기반 대시보드
    - 키워드 목록 조회, 검색 기능
    - 수집 상태 모니터링

===================================================================
4. 트러블슈팅
===================================================================

4.1 Apify 요율 제한 오류
-------------------------------------------------------------------
    증상: 429 Too Many Requests
    해결: service.py에서 asyncio.sleep(2)를 추가하여 요청 간격 조절

4.2 YouTube API 할당량 초과
-------------------------------------------------------------------
    증상: Quota exceeded
    해결: 무료 할당량(일 10,000 units)을 고려하여 검색 빈도 조절

4.3 PostgreSQL 연결 실패
-------------------------------------------------------------------
    증상: Connection refused
    해결: 
        - docker-compose.yml의 포트 확인 (5432)
        - .env의 DATABASE_URL 확인

===================================================================
5. 참고 자료
===================================================================

    - Apify 클라이언트: https://docs.apify.com/api/client/python
    - YouTube Data API: https://developers.google.com/youtube/v3
    - FastAPI 공식 문서: https://fastapi.tiangolo.com
    - SQLAlchemy 비동기: https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html

===================================================================
마무리
===================================================================

n8n의 모든 핵심 로직을 Python으로 성공적으로 이관했습니다.
이제 데이터베이스 기반 시스템으로 확장 가능하며,
GenAI 분석, 자동 발행 등의 고급 기능을 추가할 준비가 완료되었습니다.

다음 작업은 2.1~2.3 단계를 순서대로 진행해 주세요.
